[2023-02-21 21:04:23,354] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: tutorial.scraping manual__2023-02-21T20:48:51.095161+00:00 [queued]>
[2023-02-21 21:04:23,426] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: tutorial.scraping manual__2023-02-21T20:48:51.095161+00:00 [queued]>
[2023-02-21 21:04:23,434] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2023-02-21 21:04:23,442] {taskinstance.py:1239} INFO - Starting attempt 2 of 2
[2023-02-21 21:04:23,449] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2023-02-21 21:04:23,536] {taskinstance.py:1259} INFO - Executing <Task(_PythonDecoratedOperator): scraping> on 2023-02-21 20:48:51.095161+00:00
[2023-02-21 21:04:23,595] {standard_task_runner.py:52} INFO - Started process 74 to run task
[2023-02-21 21:04:23,628] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'tutorial', 'scraping', 'manual__2023-02-21T20:48:51.095161+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/reddit_ingestion_dag.py', '--cfg-path', '/tmp/tmp50kkc354', '--error-file', '/tmp/tmpikmeuvuh']
[2023-02-21 21:04:23,653] {standard_task_runner.py:77} INFO - Job 8: Subtask scraping
[2023-02-21 21:04:24,203] {logging_mixin.py:109} INFO - Running <TaskInstance: tutorial.scraping manual__2023-02-21T20:48:51.095161+00:00 [running]> on host b46f753f04a9
[2023-02-21 21:04:24,477] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=tutorial
AIRFLOW_CTX_TASK_ID=scraping
AIRFLOW_CTX_EXECUTION_DATE=2023-02-21T20:48:51.095161+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-02-21T20:48:51.095161+00:00
[2023-02-21 21:04:24,824] {logger.py:11} INFO - ====== WebDriver manager ======
[2023-02-21 21:04:27,314] {logger.py:11} INFO - Get LATEST chromedriver version for google-chrome 110.0.5481
[2023-02-21 21:04:28,510] {logger.py:11} INFO - There is no [linux64] chromedriver for browser 110.0.5481 in cache
[2023-02-21 21:04:28,517] {logger.py:11} INFO - About to download new driver from https://chromedriver.storage.googleapis.com/110.0.5481.77/chromedriver_linux64.zip
[2023-02-21 21:04:28,991] {logging_mixin.py:109} WARNING - [WDM] - Downloading:   0%|          | 0.00/7.05M [00:00<?, ?B/s]
[2023-02-21 21:04:29,108] {logging_mixin.py:109} WARNING - [WDM] - Downloading:   4%|3         | 272k/7.05M [00:00<00:02, 2.68MB/s]
[2023-02-21 21:04:29,222] {logging_mixin.py:109} WARNING - [WDM] - Downloading:  11%|#         | 792k/7.05M [00:00<00:01, 3.80MB/s]
[2023-02-21 21:04:29,337] {logging_mixin.py:109} WARNING - [WDM] - Downloading:  18%|#7        | 1.24M/7.05M [00:00<00:01, 4.02MB/s]
[2023-02-21 21:04:29,439] {logging_mixin.py:109} WARNING - [WDM] - Downloading:  30%|##9       | 2.09M/7.05M [00:00<00:00, 5.78MB/s]
[2023-02-21 21:04:29,539] {logging_mixin.py:109} WARNING - [WDM] - Downloading:  52%|#####1    | 3.65M/7.05M [00:00<00:00, 9.37MB/s]
[2023-02-21 21:04:29,639] {logging_mixin.py:109} WARNING - [WDM] - Downloading:  75%|#######4  | 5.27M/7.05M [00:00<00:00, 11.9MB/s]
[2023-02-21 21:04:29,772] {logging_mixin.py:109} WARNING - [WDM] - Downloading:  91%|#########1| 6.44M/7.05M [00:00<00:00, 10.8MB/s]
[2023-02-21 21:04:29,836] {logging_mixin.py:109} WARNING - [WDM] - Downloading: 100%|##########| 7.05M/7.05M [00:00<00:00, 8.90MB/s]
[2023-02-21 21:04:29,839] {logging_mixin.py:109} WARNING - 
[2023-02-21 21:04:32,703] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 134, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/reddit_ingestion_dag.py", line 110, in scrape_test
    scrape_keyword_from_reddit(['weclouddata'])
  File "/opt/airflow/dags/scraper.py", line 136, in scrape_keyword_from_reddit
    result = search_keywords_in_reddit(cmp)
  File "/opt/airflow/dags/scraper.py", line 46, in search_keywords_in_reddit
    driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/chrome.py", line 39, in install
    driver_path = self._get_driver_path(self.driver)
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/manager.py", line 31, in _get_driver_path
    binary_path = self.driver_cache.save_file_to_cache(driver, file)
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/driver_cache.py", line 50, in save_file_to_cache
    browser_version, driver_name, os_type, unified_version, binary_path
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/driver_cache.py", line 77, in __save_metadata
    metadata = self.get_metadata()
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/driver_cache.py", line 135, in get_metadata
    return json.load(outfile)
  File "/usr/local/lib/python3.7/json/__init__.py", line 296, in load
    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
[2023-02-21 21:04:32,932] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=tutorial, task_id=scraping, execution_date=20230221T204851, start_date=20230221T210423, end_date=20230221T210432
[2023-02-21 21:04:33,096] {standard_task_runner.py:92} ERROR - Failed to execute job 8 for task scraping
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 134, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/reddit_ingestion_dag.py", line 110, in scrape_test
    scrape_keyword_from_reddit(['weclouddata'])
  File "/opt/airflow/dags/scraper.py", line 136, in scrape_keyword_from_reddit
    result = search_keywords_in_reddit(cmp)
  File "/opt/airflow/dags/scraper.py", line 46, in search_keywords_in_reddit
    driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/chrome.py", line 39, in install
    driver_path = self._get_driver_path(self.driver)
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/manager.py", line 31, in _get_driver_path
    binary_path = self.driver_cache.save_file_to_cache(driver, file)
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/driver_cache.py", line 50, in save_file_to_cache
    browser_version, driver_name, os_type, unified_version, binary_path
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/driver_cache.py", line 77, in __save_metadata
    metadata = self.get_metadata()
  File "/home/airflow/.local/lib/python3.7/site-packages/webdriver_manager/core/driver_cache.py", line 135, in get_metadata
    return json.load(outfile)
  File "/usr/local/lib/python3.7/json/__init__.py", line 296, in load
    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
[2023-02-21 21:04:33,245] {local_task_job.py:154} INFO - Task exited with return code 1
[2023-02-21 21:04:33,661] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
