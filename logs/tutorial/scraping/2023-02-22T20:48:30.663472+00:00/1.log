[2023-02-23 22:46:14,440] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: tutorial.scraping scheduled__2023-02-22T20:48:30.663472+00:00 [queued]>
[2023-02-23 22:46:14,466] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: tutorial.scraping scheduled__2023-02-22T20:48:30.663472+00:00 [queued]>
[2023-02-23 22:46:14,468] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2023-02-23 22:46:14,469] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2023-02-23 22:46:14,471] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2023-02-23 22:46:14,523] {taskinstance.py:1259} INFO - Executing <Task(_PythonDecoratedOperator): scraping> on 2023-02-22 20:48:30.663472+00:00
[2023-02-23 22:46:14,536] {standard_task_runner.py:52} INFO - Started process 81409 to run task
[2023-02-23 22:46:14,559] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'tutorial', 'scraping', 'scheduled__2023-02-22T20:48:30.663472+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/reddit_ingestion_dag.py', '--cfg-path', '/tmp/tmp9g4dr1no', '--error-file', '/tmp/tmpppocw2uv']
[2023-02-23 22:46:14,564] {standard_task_runner.py:77} INFO - Job 54: Subtask scraping
[2023-02-23 22:46:14,736] {logging_mixin.py:109} INFO - Running <TaskInstance: tutorial.scraping scheduled__2023-02-22T20:48:30.663472+00:00 [running]> on host 541881d0ad34
[2023-02-23 22:46:14,911] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=tutorial
AIRFLOW_CTX_TASK_ID=scraping
AIRFLOW_CTX_EXECUTION_DATE=2023-02-22T20:48:30.663472+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-02-22T20:48:30.663472+00:00
[2023-02-23 22:46:15,534] {logger.py:11} INFO - ====== WebDriver manager ======
[2023-02-23 22:46:17,330] {logger.py:11} INFO - Get LATEST chromedriver version for google-chrome 110.0.5481
[2023-02-23 22:46:18,634] {logger.py:11} INFO - Driver [/home/***/.wdm/drivers/chromedriver/linux64/110.0.5481/chromedriver] found in cache
[2023-02-24 00:46:04,979] {local_task_job.py:212} WARNING - State of this instance has been externally set to up_for_retry. Terminating instance.
[2023-02-24 00:46:05,068] {process_utils.py:124} INFO - Sending Signals.SIGTERM to group 81409. PIDs of all processes in the group: [81434, 81440, 81444, 81445, 81451, 81452, 81469, 81477, 81527, 81512, 81409]
[2023-02-24 00:46:05,090] {process_utils.py:75} INFO - Sending the signal Signals.SIGTERM to group 81409
[2023-02-24 00:46:05,123] {taskinstance.py:1408} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-02-24 00:46:05,235] {process_utils.py:70} INFO - Process psutil.Process(pid=81440, status='terminated', started='22:46:19') (81440) terminated with exit code None
[2023-02-24 00:46:05,238] {process_utils.py:70} INFO - Process psutil.Process(pid=81469, status='terminated', started='22:46:20') (81469) terminated with exit code None
[2023-02-24 00:46:05,245] {process_utils.py:70} INFO - Process psutil.Process(pid=81451, status='terminated', started='22:46:20') (81451) terminated with exit code None
[2023-02-24 00:46:05,252] {process_utils.py:70} INFO - Process psutil.Process(pid=81444, status='terminated', started='22:46:19') (81444) terminated with exit code None
[2023-02-24 00:46:05,256] {process_utils.py:70} INFO - Process psutil.Process(pid=81527, status='terminated', started='22:46:24') (81527) terminated with exit code None
[2023-02-24 00:46:05,260] {process_utils.py:70} INFO - Process psutil.Process(pid=81512, status='terminated', started='22:46:21') (81512) terminated with exit code None
[2023-02-24 00:46:05,261] {process_utils.py:70} INFO - Process psutil.Process(pid=81445, status='terminated', started='22:46:19') (81445) terminated with exit code None
[2023-02-24 00:46:05,263] {process_utils.py:70} INFO - Process psutil.Process(pid=81477, status='terminated', started='22:46:20') (81477) terminated with exit code None
[2023-02-24 00:46:05,265] {process_utils.py:70} INFO - Process psutil.Process(pid=81452, status='terminated', started='22:46:20') (81452) terminated with exit code None
[2023-02-24 00:46:05,259] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 134, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/reddit_ingestion_dag.py", line 582, in scrape_test
    scrape_keyword_from_reddit(competitors) # starlights waz
  File "/opt/airflow/dags/scraper.py", line 137, in scrape_keyword_from_reddit
    result = search_keywords_in_reddit(cmp.lower())
  File "/opt/airflow/dags/scraper.py", line 49, in search_keywords_in_reddit
    driver.get("https://www.reddit.com/?feed=home")
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 449, in get
    self.execute(Command.GET, {"url": url})
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 438, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py", line 290, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py", line 311, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/request.py", line 79, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/poolmanager.py", line 375, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 706, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.7/http/client.py", line 1373, in getresponse
    response.begin()
  File "/usr/local/lib/python3.7/http/client.py", line 319, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.7/http/client.py", line 280, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-02-24 00:46:05,303] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=tutorial, task_id=scraping, execution_date=20230222T204830, start_date=20230223T224614, end_date=20230224T004605
[2023-02-24 00:46:05,343] {standard_task_runner.py:92} ERROR - Failed to execute job 54 for task scraping
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 134, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/reddit_ingestion_dag.py", line 582, in scrape_test
    scrape_keyword_from_reddit(competitors) # starlights waz
  File "/opt/airflow/dags/scraper.py", line 137, in scrape_keyword_from_reddit
    result = search_keywords_in_reddit(cmp.lower())
  File "/opt/airflow/dags/scraper.py", line 49, in search_keywords_in_reddit
    driver.get("https://www.reddit.com/?feed=home")
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 449, in get
    self.execute(Command.GET, {"url": url})
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 438, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py", line 290, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py", line 311, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/request.py", line 79, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/poolmanager.py", line 375, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 706, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 445, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 440, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.7/http/client.py", line 1373, in getresponse
    response.begin()
  File "/usr/local/lib/python3.7/http/client.py", line 319, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.7/http/client.py", line 280, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1410, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-02-24 00:46:05,394] {process_utils.py:70} INFO - Process psutil.Process(pid=81409, status='terminated', exitcode=1, started='22:46:13') (81409) terminated with exit code 1
[2023-02-24 00:46:05,401] {process_utils.py:70} INFO - Process psutil.Process(pid=81434, status='terminated', started='22:46:17') (81434) terminated with exit code None
